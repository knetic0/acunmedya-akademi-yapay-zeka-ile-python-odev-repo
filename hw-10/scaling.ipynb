{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86041443",
   "metadata": {},
   "source": [
    "# Özellik Ölçekleme (Feature Scaling)\n",
    "\n",
    "Özellik ölçekleme, makine öğrenmesi modellerinin farklı ölçeklerdeki özelliklerle daha iyi çalışması için özellik değerlerinin belli bir aralığa veya dağılıma dönüştürülmesi işlemidir. Ölçeklendirme yapılmadığında, bazı algoritmalar (örneğin K-Means, KNN, SVM, regresyon) büyük değere sahip özelliklere daha fazla ağırlık vererek yanlı sonuçlar üretebilir.\n",
    "\n",
    "## Neden Gereklidir?\n",
    "- **Kümeleme ve Mesafe Tabanlı Yöntemler**: Özellik değerleri arasındaki mutlak farklar mesafe ölçümlerini etkiler.\n",
    "- **Optimizasyon**: Gradient Descent gibi optimizasyon yöntemlerinde farklı ölçekli değişkenler öğrenme hızını yavaşlatabilir.\n",
    "- **Düzenleme (Regularization)**: L1 ve L2 cezalarında özellik büyüklüğü cezayı doğrudan etkiler.\n",
    "\n",
    "## Yaygın Ölçekleme Yöntemleri\n",
    "\n",
    "1. **Standardizasyon (Z-Score)**\n",
    "   - Özellikler, ortalaması 0 ve standart sapması 1 olacak şekilde dönüştürülür.\n",
    "\n",
    "2. **Min-Max Ölçekleme**\n",
    "   - Değerler [0, 1] aralığına sıkıştırılır.  \n",
    "\n",
    "3. **Robust Ölçekleme**\n",
    "   - Özellikle aykırı değerlerden (outlier) etkilenmeyi azaltmak için medyan ve çeyrekler arası açıklık (IQR) kullanılır.\n",
    "\n",
    "4. **MaxAbs Ölçekleme**\n",
    "   - Özellik değerleri [-1,1] aralığına ölçeklenir, sıfır merkezli kalır.\n",
    "\n",
    "5. **Normalizasyon (Birim Vektör)**\n",
    "   - Her örnek kendi vektör uzunluğuna bölünerek uzunluğu 1 olacak şekilde dönüştürülür.\n",
    "\n",
    "## Python ile Uygulama\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer\n",
    "\n",
    "X = load_iris().data\n",
    "\n",
    "# 1. StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_std = std_scaler.fit_transform(X)\n",
    "\n",
    "# 2. MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_mm = mm_scaler.fit_transform(X)\n",
    "\n",
    "# 3. RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "X_robust = robust_scaler.fit_transform(X)\n",
    "\n",
    "# 4. MaxAbsScaler\n",
    "maxabs_scaler = MaxAbsScaler()\n",
    "X_maxabs = maxabs_scaler.fit_transform(X)\n",
    "\n",
    "# 5. Normalizer\n",
    "normalizer = Normalizer()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "```\n",
    "\n",
    "## Hangi Yöntem Seçilmeli?\n",
    "- **Aykırı Değerler Var**: RobustScaler  \n",
    "- **Dağılımı Koruma**: StandardScaler  \n",
    "- **Sıkıştırma**: MinMaxScaler  \n",
    "- **Sıfır Merkezli Kalmak**: MaxAbsScaler  \n",
    "- **Örnek Bazlı Uzunluk**: Normalizer  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2e3f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
